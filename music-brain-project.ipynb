{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Brain Project\n",
    "\n",
    "*Can we guess how you will react to music?*\n",
    "\n",
    "\n",
    "In the Spring of 2019, me (Ted Lewitt), Ben Hahn and Jack Elliott partnered with the Brain and Creativity Institute at USC to use deep learning methods to predict patients response to instrumental music.\n",
    "\n",
    "### The Dataset\n",
    "\n",
    "36 Patients went into a MRI and listened to 5 minute long instrumental songs that were either meant to be uplifting or sad. The MRI recorded their brain activations and the patients used a sliding scale to represent how they felt while listening to the music. \n",
    "\n",
    "![fd](Images/glass_brain.png \"A sample MRI image\")\n",
    "\n",
    "### Our Hypothesis\n",
    "\n",
    "We can use a recurrent nueral network to predict how a patient felt at a moment in time, based off the MRI data from that moment. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import helperFunctions as hf\n",
    "import keras\n",
    "from keras import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation,Dense\n",
    "from keras.layers.recurrent import LSTM\n",
    "import nilearn\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "**Data Types** <br>\n",
    "\n",
    "+ The MRI data file is known as fMRI and is stored in a NIFTI file (suffix .nii). It is a time series of MRI data, with each time step being a 3D volumetric snapshot of brain activations.\n",
    "\n",
    "+ The slider data was a text file with timestamps and activations, on a scale of 0 to 127, with 127 being very happy and 0 being very sad.\n",
    "\n",
    "### Preprocessing the Slider Data\n",
    "\n",
    "**Initial Steps**\n",
    "\n",
    "- The fMRI data was at 1 Hz but the slider data was at 30 Hz, so we had to down-sample the slider data to match the fMRI data.\n",
    "- We scaled the slider data to be on a scale of (0,1) from (0,127).\n",
    "\n",
    "- Human brains take an average of 6 seconds to process the music, so we need to add a 6 second delay between the slider data and the MRI image.\n",
    "\n",
    "**Bucketing the Data & Switching from Regression to Classification** <br>\n",
    "\n",
    "We were having issues with regressing the data (see our conculsions section for more info) so we decided to switch to a classsification problem using data bucketing.\n",
    "![Bucket](Images/binning.png \"An example of bucketing data\")\n",
    "\n",
    "Data bucketing transforms a continous variable (our slider data) into a discrete variable by taking all the continous data that lies in a certain area and lumping it all together in one bucket. In our example, all the continous slider data above 67.5 can be bucketed into the **Happy** bucket and all the data below 67.5 is bucketed into the **Sad** bucket. This allows us to use one hot encoding to represent the different classes, depending on how many buckets we decide to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-1-263b007d4f18>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-263b007d4f18>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    def down_sample(array,NUM_BUCKETS):\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "NUM_BUCKETS = 2 # or 4\n",
    "def preprocess_slider_data(data_file):\n",
    "    data = load_data()\n",
    "    down_sampled_data = down_sample(data)\n",
    "    bucket_data = bucket(down_sampled_data,NUM_BUCKETS)\n",
    "    return bucket_data\n",
    "def load_data(file):\n",
    "    \n",
    "def down_sample(array,NUM_BUCKETS):\n",
    "\n",
    "def bucket(data,buckets):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the MRI Data\n",
    "We used the niLearn package to transform our 4D fMRI (time steps, 3 spatial dimensions) to a 2D time series (time steps,\n",
    "features). The initial shape of the input tensor was (495,100,90,100) and we wanted it to be (495,#Features) so it could be fed into our Tensorflow LSTM.\n",
    "\n",
    "NiLearn has a class called NiftiMasker that does exactly that, transforming our data into an (495,250000) shaped time series. (This number of features is incedibly high we know, see our conclusions for more). <br>\n",
    "![dg](Images/masking1.jpg \"Illustration of Nifti Masker\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Ipython import Image\n",
    "Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_time_series(mri_file):\n",
    "    nifti_masker = nilearn.input_data.NiftiMasker(standardize=True, mask_strategy='template')\n",
    "    indexer = [i for i in range(0,495-DELAY)]\n",
    "    #Split the fMRI data into 495 consecutive images\n",
    "    result=nilearn.image.index_img(mri_file,indexer)\n",
    "    nifti_masker.fit(result)\n",
    "    masked=nifti_masker.transform(result)\n",
    "    masked=np.array(masked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep track of which label data corresponded to which MRI data, the patients given an ID, so we load the data based on the ID.\n",
    "This step does all the preprocessing and will take a long time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_files_dir = \"\"\n",
    "mri_files_dir = \"\"\n",
    "\n",
    "for count in range(1,40):\n",
    "    if count<10:\n",
    "        count=str(0)+str(count)\n",
    "    \n",
    "    #First we preprocess the nii file\n",
    "    niifile=\"patient_\"+str(count)+\".nii\"\n",
    "    labelfile = \"patient_\"+str(count)+\".txt\"\n",
    "    fullfile = os.path.join(txt_files_dir,labelfile)\n",
    "    fullNii=os.path.join(mri_files_dir,niifile)\n",
    "    try:\n",
    "        nii, sizeValue = create_time_series(fullNii)        \n",
    "        label = np.array(preprocess_slider_data(fullfile)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Incomplete Data for Patient %d\" % count)\n",
    "                         \n",
    "\n",
    "nii_array=np.array(nii_array)\n",
    "label_array=np.array(label_array)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalFiles=len(label_array)\n",
    "\n",
    "train_labels, test_labels, train_nii, test_nii=train_test_split(label_array, nii_array, train_size=.75, test_size=.25)\n",
    "\n",
    "train_labels = np.array(train_labels)\n",
    "train_nii = np.array(train_nii)\n",
    "test_labels = np.array(test_labels)\n",
    "test_nii = np.array(test_nii)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "\n",
    "These are the optimal hyperparameters we found for our model.\n",
    "See PostProcessing for an discussion on other hyperparameters we explored for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 4\n",
    "BATCH_SIZE = 5\n",
    "if NUM_BUCKETS == 2: \n",
    "    LOSS = 'binary_cross_entropy'\n",
    "    METRICS = [metrics.binary_accuracy]\n",
    "else:\n",
    "    LOSS = 'categorical_crossentropy'\n",
    "    METRICS = [metrics.categorical_accuracy]\n",
    "OPTIMIZER = 'Adam'\n",
    "inputShape = (495-DELAY,sizeValue)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "We decided to use the Keras implementation of the Long Short-Term Memory RNN becuase of the time series nature of the data. Also the human brain has the memory of the whole song when forming emotions, so we needed a model that also had this capability. The strength of the LSTM to capture both short term trends and keep a longer memory suited our needs well.\n",
    "\n",
    "To predict a bucket over all 495 time steps at the same time we added the TimeDistributed Dense Layer. This means the model's output was a (495,NUM_BUCKETS) matrix with one hot encoding fo the predicted bucket.\n",
    "\n",
    "ADD PICTURE FROM SLIDE 6 OF CAIS FINAL PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Initilization\n",
    "model=Sequential()\n",
    "\n",
    "model.add(LSTM(units=inputShape[0], activation='tanh', dropout=.15, input_shape=inputShape, return_sequences=True))\n",
    "\n",
    "model.add(keras.layers.TimeDistributed(Dense(NUM_BUCKETS,activation='softmax')))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training\n",
    "model.compile(loss=LOSS,optimizer=OPTIMIZER, metrics=METRICS)\n",
    "\n",
    "model.fit(train_nii,train_labels,epochs=EPOCHS,batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaulation\n",
    "score=model.evaluate(test_nii,test_labels,verbose=1, batch_size=4)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HyperParameter Tuning\n",
    "\n",
    "To find optimal hyperparameters, we used a naive grid search method, combining all of the following options:\n",
    "\n",
    "**Epochs**- [4,8,12,16] <br>\n",
    "**Batch Size** - [5,10] <br>\n",
    "**Dropout** - [.08,.15,.25,.40] <br>\n",
    "**Number of Buckets**- [2,4,10] <br>\n",
    "\n",
    "The optimal combination we found is: <br>\n",
    "**Epochs**: 4 <br>\n",
    "**Batch Size**: 5 <br>\n",
    "**Dropout**: .15 <br>\n",
    "**Number of Buckets**: 2 <br> \n",
    "\n",
    "We found the model has major issues overfitting, so less epochs performed better.\n",
    "\n",
    "We also found less buckets made the model more accurate, which intiutively makes sense becuase it has a much larger range of error with one bucket instead of two.\n",
    "\n",
    "### Best Results\n",
    "+ 88% Accuracy with 2 Buckets\n",
    "+ 32% Accuracy with 4 Buckets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Our project was a failure. We didnt acheive high accuracy and it doesn't seem like our model learned anything about the human brain. That doesn't mean that we did not learn a lot. Analyzing why it didn't work has been a huge learning experience for us and will help us on future projects. Here is an non-exasutive list of things that went wrong.\n",
    "\n",
    "+ **Lack of Domain Knowledge in Preprocessing** We had no domain knowledge in the field of fMRI, so we blindly used the niLearn preprocessing with little understanding of the methods behind it.\n",
    "+ **Too Many Features and Too Little Data** Our feature space was over 250,000 features, far too many for any predictive model, even with an massive dataset. Our model could never hope to accurately use them all and suffered accordingly. Even if we could have reduced the feature space, we still only had 17,325 (495 seconds X 35 people) instances in our full dataset. \n",
    "+ **Oversimplification of the Human Brain** Even if we had an incredibly powerful model, human brains are intricate and work in complex ways so trying to model it this way makes a lot of assumption. At the time of writing this, the most accurate paper (Bandettini et al)[https://www.sciencedirect.com/science/article/abs/pii/S1053811918320263] we could find has 50% accuracy with 4 buckets, showing how even the state of the art methods still struggle with modeling the human brain.\n",
    "\n",
    "\n",
    "\n",
    "## Future Steps\n",
    "\n",
    "+ **Try a CNN_LSTM** Instead of using niLearn to preprocess our data, feed the MRI data directly into a 3D Convolutional Neural Network and pass it's output into the LSTM. This will be much more challenging to train and our dataset is far too small, but could see some improvements due to the CNN's ability to capture spatial features.\n",
    "\n",
    "+ **Reduce the Feature Space using ROIs** Try only using certain parts of the brain (Regions of Interest) that are known to strongly correlate to music and or emotion to reduce the feature space to a subsection of the brain. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
