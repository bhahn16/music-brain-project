{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Brain Project\n",
    "\n",
    "Can we guess how you will react to music?\n",
    "\n",
    "\n",
    "In the spring of 2020, me (Ted Lewitt), Ben Hahn and Jack Elliott partnered with the Brain and Creativity Institute at USC to use deep learning methods to predict patients response to instrumental music.\n",
    "\n",
    "### The Dataset\n",
    "\n",
    "36 Patients went into a MRI and listened to 5 minute long instrumental songs that were either meant to be uplifting or sad. The MRI recorded their brain activations and the patients used a sliding scale to represent how they felt while listening to the music.\n",
    "\n",
    "### Our Hypothesis\n",
    "\n",
    "We can use a recurrent nueral network to predict how a patient felt at a moment in time, based off the MRI data from that moment. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import helperFunctions as hf\n",
    "import keras\n",
    "from keras import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation,Dense\n",
    "from keras.layers.recurrent import LSTM\n",
    "import nilearn\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "**DATA TYPES**\n",
    "The MRI data was actually a fMRI, so it was a series of MRI data, which itself was a 3D volumetric matrix of brain activations.\n",
    "The slider data was a text file with timestamps and activations, on a scale of 0 to 127, with 127 being very happy and 0 being very sad.\n",
    "\n",
    "### Preprocessing the Slider Data\n",
    "**INITIAL STEPS**\n",
    "\n",
    "- The fMRI data was at 1 Hz but the slider data was at 30 Hz, so we had to down-sample the data.\n",
    "- We used the average of the 30 measurements taken as the measurement for the one second.\n",
    "- We also scaled the slider data to be on a scale of 0,1.\n",
    "- Human brains take an average of 6 seconds to process the music, so we need to add a 6 second delay between the slider data and the MRI image.\n",
    "**Bucketing the Data & Switching to Classification**\n",
    "We were having issues with regressing the data (see our conculsions section for more info) so we decided to switch to a classsification problem, transforming our slider data from a scalar to a class, either Happy or Sad.\n",
    "\n",
    "\n",
    "### Preprocessing the MRI Data\n",
    "We used the niLearn package to transform our 4D fMRI (time steps, 3 spatial dimensions) to a 2D time series (time steps,\n",
    "features). The initial shape of the input tensor was (495,100,90,100) and we wanted it to be (495,#Features) so it could be fed into our Tensorflow LSTM.\n",
    "NiLearn has a class called NiftiMasker that does exactly that, transforming our data into an (495,250000) shaped time series. (This number of features is incedibly high we know, see our conclusions for more).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_BUCKETS = 2 # or 4\n",
    "def preprocess_slider_data(data_file):\n",
    "    data = load_data()\n",
    "    down_sampled_data = down_sample(data)\n",
    "    bucket_data = bucket(data,NUM_BUCKETS)\n",
    "    return bucket_data\n",
    "def load_data(file):\n",
    "    \n",
    "def down_sample(array,NUM_BUCKETS):\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_time_series(mri_file):\n",
    "    nifti_masker = nilearn.input_data.NiftiMasker(standardize=True, mask_strategy='template')\n",
    "    indexer = [i for i in range(0,495-DELAY)]\n",
    "    #Split the fMRI data into 495 consecutive images\n",
    "    result=nilearn.image.index_img(mri_file,indexer)\n",
    "    nifti_masker.fit(result)\n",
    "    masked=nifti_masker.transform(result)\n",
    "    masked=np.array(masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_files_dir = \"\"\n",
    "mri_files_dir = \"\"\n",
    "\n",
    "for count in range(1,40):\n",
    "    gotlabel=False\n",
    "    gotnii=False\n",
    "    if count<10:\n",
    "        count=str(0)+str(count)\n",
    "    \n",
    "    #First we preprocess the nii file\n",
    "    niifile=\"sub-\"+str(count)+\"_sadln_filtered_func_200hpf_standard_aroma.nii\"\n",
    "    else:\n",
    "        fullNii=os.path.join(mri_files_dir,niifile)\n",
    "        if os.path.isfile(fullNii):\n",
    "            nii, sizeValue = create_time_series(fullNii)\n",
    "            gotnii = True\n",
    "            \n",
    "    #Next up is the corresponding label data\n",
    "        labelfile = \"sub-\"+str(count)+\"_snl_l_enjoy_log.txt\"\n",
    "        fullfile = os.path.join(txt_files_dir,labelfile)\n",
    "        if os.path.isfile(fullfile):        \n",
    "            label = np.array(preprocess_slider_data(fullfile)\n",
    "            gotlabel = True \n",
    "            \n",
    "    if gotlabel and gotnii:\n",
    "        nii_array.append(nii)\n",
    "        label_array.append(label)\n",
    "\n",
    "nii_array=np.array(nii_array)\n",
    "label_array=np.array(label_array)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalFiles=len(label_array)\n",
    "\n",
    "train_labels, test_labels, train_nii, test_nii=train_test_split(label_array, nii_array, train_size=.75, test_size=.25)\n",
    "\n",
    "train_labels = np.array(train_labels)\n",
    "train_nii = np.array(train_nii)\n",
    "test_labels = np.array(test_labels)\n",
    "test_nii = np.array(test_nii)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "\n",
    "See PostProcessing for an discussion on optimal hyperparameters we explored for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 4\n",
    "BATCH_SIZE = 5\n",
    "if NUM_BUCKETS == 2: \n",
    "    LOSS = 'binary_cross_entropy'\n",
    "    METRICS = [metrics.binary_accuracy]\n",
    "else:\n",
    "    LOSS = 'categorical_crossentropy'\n",
    "    METRICS = [metrics.categorical_accuracy]\n",
    "OPTIMIZER = 'Adam'\n",
    "inputShape = (495-DELAY,sizeValue)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "We decided to use the Keras implementation of the Long Short-Term Memory RNN becuase of the time series nature of the data. Also the human brain has the memory of the whole song when forming emotions, so we needed a model that also had this capability. The strength of the LSTM to capture both short term trends and keep a longer memory suited our needs well.\n",
    "\n",
    "To predict a bucket over all 495 time steps at the same time we added the TimeDistributed Dense Layer. This means the model's output was a (495,NUM_BUCKETS) matrix with one hot encoding fo the predicted bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Initilization\n",
    "model=Sequential()\n",
    "\n",
    "model.add(LSTM(units=inputShape[0], activation='tanh', dropout=.15, input_shape=inputShape, return_sequences=True))\n",
    "\n",
    "model.add(keras.layers.TimeDistributed(Dense(NUM_BUCKETS,activation='softmax')))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training\n",
    "model.compile(loss=LOSS,optimizer=OPTIMIZER, metrics=METRICS)\n",
    "\n",
    "model.fit(train_nii,train_labels,epochs=EPOCHS,batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaulation\n",
    "score=model.evaluate(test_nii,test_labels,verbose=1, batch_size=4)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HyperParameter Tuning\n",
    "\n",
    "For optimal hyperparameters, we used a naive grid method, combining all of the following options:\n",
    "\n",
    "Epochs- [3,5,10,15]\n",
    "Batch Size - [5,10]\n",
    "Dropout - [.08,.15,.25,.40]\n",
    "Number of Buckets- [2,4,10]\n",
    "\n",
    "The optimal combination we found is:\n",
    "Epochs: 4\n",
    "Batch Size: 5\n",
    "Dropout: .15\n",
    "Number of Buckets: 2 \n",
    "\n",
    "We found the model has major issues overfitting, so less epochs actually was performing better.\n",
    "\n",
    "We also found less buckets made the model more accurate, which intiutively makes sense becuase it has a much larger range of error with one bucket instead of two.\n",
    "\n",
    "### Best Results\n",
    "88% Accuracy with 2 Buckets\n",
    "35% Accuracy with 4 Buckets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Our project was a failure. REWORD We didnt acheive high accuracy and it doesn't seem like our model learned anything about the human brain. That doesn't mean that we did not learn a lot. Analyzing why it didn't work has been a huge learning experience for us and will help us on future projects. Here is an non-exasutive list of things that went wrong\n",
    "\n",
    "**Lack of Domain Knowledge in Preprocessing** We had no domain knowledge in the field of fMRI, so we blindly used the niLearn preprocessing with little understanding of the methods behind it.\n",
    "**Too Many Features and Too Little Data** Our feature space was over 250,000 features, far too many for any predictive model, even with an massive dataset. Our model could never hope to accurately use them all and suffered accordingly. Even if we could have reduced the feature space, we still only had 17,325 (495 seconds X 35 people) instances in our full dataset. \n",
    "**Oversimplification of the Human Brain** Even if we had an incredibly powerful model, human brains are intricate and work in complex ways so trying to model it this way makes a lot of assumption. At the time of writing this, the most accurate paper (Bandettini et al)[https://www.sciencedirect.com/science/article/abs/pii/S1053811918320263] we could find has 50% accuracy with 4 buckets, showing how even the state of the art methods still struggle with modeling the human brain.\n",
    "\n",
    "\n",
    "\n",
    "## Future Steps\n",
    "\n",
    "**Try a CNN_LSTM** Instead of using niLearn to preprocess our data, feed the MRI data directly into a 3D Convolutional Neural Network and pass it's output into the LSTM. This will be much more challenging to train and our dataset is far too small, but could see some improvements due to the CNN's ability to capture spatial features.\n",
    "**Reduce the Feature Space using ROIs** Try only using certain parts of the brain that are known to strongly correlate to music and or emotion to reduce the feature space to a subsection of the brain. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
